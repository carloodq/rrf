{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u26pNdTjadng"
      },
      "outputs": [],
      "source": [
        "!pip install -q weaviate-client\n",
        "!pip install -q PyPDF2\n",
        "!pip install -q openai\n",
        "!pip install -q keybert\n",
        "!pip install -q keybert[flair]\n",
        "!pip install -q keybert[gensim]\n",
        "!pip install -q keybert[spacy]\n",
        "!pip install -q keybert[use]\n",
        "!pip install -q git+http://github.com/LIAAD/yake\n",
        "!pip install -q langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B-Z4i6yUiP2b"
      },
      "outputs": [],
      "source": [
        "from pprint import pprint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlub40k1a_6O"
      },
      "source": [
        "## Data (examples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1AOPh_cjC1d"
      },
      "source": [
        "### Functions"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc1 = '1706.03762.pdf'\n",
        "doc2 = ''"
      ],
      "metadata": {
        "id": "g9E64y3AVTiH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RWNtEYbnjGDO"
      },
      "outputs": [],
      "source": [
        "from PyPDF2 import PdfReader\n",
        "def read_pdf(file_path: str) -> str:\n",
        "    with open(file_path, \"rb\") as file:\n",
        "        pdf_reader = PdfReader(file)\n",
        "        text = \"\"\n",
        "        for page_num in range(len(pdf_reader.pages)):\n",
        "            text += pdf_reader.pages[page_num].extract_text()\n",
        "    return text\n",
        "\n",
        "\n",
        "def chunking(some_text: str) -> list[str]:\n",
        "  from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "  r_splitter = RecursiveCharacterTextSplitter(\n",
        "      chunk_size=150,\n",
        "      chunk_overlap=0,\n",
        "      separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
        "  )\n",
        "  return r_splitter.split_text(some_text)\n",
        "\n",
        "\n",
        "def chunking_md(some_text: str) -> list[str]:\n",
        "  from langchain.text_splitter import MarkdownHeaderTextSplitter\n",
        "\n",
        "\n",
        "  headers_to_split_on = [\n",
        "      (\"#\", \"Header 1\"),\n",
        "      (\"##\", \"Header 2\"),\n",
        "      (\"###\", \"Header 3\"),\n",
        "  ]\n",
        "\n",
        "  markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n",
        "  md_header_splits = markdown_splitter.split_text(some_text)\n",
        "\n",
        "  return md_header_splits\n",
        "\n",
        "def extract_kws_bert(doc: str) -> list[str]:\n",
        "  from keybert import KeyBERT\n",
        "  kw_model = KeyBERT()\n",
        "  keywords = kw_model.extract_keywords(doc)\n",
        "  return [x[0] for x in keywords]\n",
        "\n",
        "def extract_kws(doc: str) -> list[str]:\n",
        "  import yake\n",
        "  custom_kw_extractor = yake.KeywordExtractor(lan=\"en\")\n",
        "  keywords = custom_kw_extractor.extract_keywords(doc)\n",
        "  return [x[0] for x in keywords]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NHAmEeUotGN"
      },
      "source": [
        "### Queries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6kOljywybhpo"
      },
      "outputs": [],
      "source": [
        "query_1 = 'Which are some popular libraries of bioinformatics ?'\n",
        "\n",
        "query_2 = 'Which applications can I develop using Reinforcement Learning?'\n",
        "\n",
        "query_3 = 'Where is CapitaLand Investment Limited incorporated ?'\n",
        "\n",
        "query_4 = 'Can you make a 30 words summary of the Message to Shareholders?'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rMHAKS8bbGH"
      },
      "source": [
        "### Regulations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5GmaRiZygyAE"
      },
      "outputs": [],
      "source": [
        "doc_1 = read_pdf(doc1)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc_1 = doc_1[:int(len(doc_1)*0.1)]"
      ],
      "metadata": {
        "id": "kpk3AHFGc4Rs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WxF7S6Sqov8E"
      },
      "outputs": [],
      "source": [
        "documents = [doc_1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_cXtbrYcaJF"
      },
      "source": [
        "## Vector DB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EG0ncE_itBx"
      },
      "source": [
        "### Client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oGxOobB4dHuE"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from typing import Any\n",
        "\n",
        "import weaviate\n",
        "from google.colab import userdata\n",
        "from weaviate.client import WeaviateClient\n",
        "\n",
        "\n",
        "class WeaviateClientSession:\n",
        "    def __init__(self, version: str = '1.23.7') -> None:\n",
        "        self.version = version\n",
        "        self.client = weaviate.connect_to_embedded(\n",
        "            version=self.version,\n",
        "            headers={\n",
        "                \"X-OpenAI-Api-Key\": userdata.get('OPENAI_API_KEY'),  # os.getenv('OPENAI_API_KEY'),\n",
        "            },\n",
        "            persistence_data_path='./db',\n",
        "        )\n",
        "\n",
        "    def __enter__(self) -> WeaviateClient:\n",
        "        self.client.connect()\n",
        "        return self.client\n",
        "\n",
        "    def __exit__(self, exc_type: type, exc_value: Exception, traceback: Any) -> None:\n",
        "        self.client.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fM6kN1p6f7vG"
      },
      "source": [
        "### Create collection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oSkOxC-peJ26"
      },
      "outputs": [],
      "source": [
        "import weaviate.classes as wvc\n",
        "\n",
        "\n",
        "with WeaviateClientSession() as client:\n",
        "  client.collections.create(\n",
        "        name='Documents',\n",
        "        properties=[\n",
        "            wvc.config.Property(\n",
        "                name='document_id',\n",
        "                data_type=wvc.config.DataType.INT,\n",
        "                skip_vectorization=True,\n",
        "            ),\n",
        "            wvc.config.Property(\n",
        "                name='chunk_text',\n",
        "                data_type=wvc.config.DataType.TEXT,\n",
        "                skip_vectorization=False,\n",
        "            ),\n",
        "            wvc.config.Property(\n",
        "                name='chunk_index',\n",
        "                data_type=wvc.config.DataType.INT,\n",
        "                skip_vectorization=True,\n",
        "            ),\n",
        "            wvc.config.Property(\n",
        "                name='keywords',\n",
        "                data_type=wvc.config.DataType.TEXT,\n",
        "                skip_vectorization=True,\n",
        "                tokenization=wvc.config.Tokenization.WHITESPACE,\n",
        "            ),\n",
        "        ],\n",
        "        vectorizer_config=wvc.config.Configure.Vectorizer.text2vec_openai('text-embedding-3-small'),\n",
        "        generative_config=wvc.config.Configure.Generative.openai(model='gpt-3.5-turbo'),\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BlCsWSZhg2k0"
      },
      "outputs": [],
      "source": [
        "with WeaviateClientSession() as client:\n",
        "  pprint(client.collections.list_all())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLJe6plcgBXf"
      },
      "source": [
        "### Store document chunks and keywords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bxfgG3aKjdgz"
      },
      "outputs": [],
      "source": [
        "def prepare_doc_objs(docs: list[str]) -> list[dict]:\n",
        "  doc_objs = []\n",
        "\n",
        "  for doc_id, doc in enumerate(docs):\n",
        "    # Chunk documents\n",
        "    chunks: list[str] = chunking(doc)\n",
        "\n",
        "    # Retrieve document keywords using GPT\n",
        "    doc_keywords: list[str] = extract_kws(doc)\n",
        "\n",
        "    for idx, chunk in enumerate(chunks):\n",
        "      # Retrieve chunk keywords using GPT\n",
        "      chunk_keywords: list[str] = extract_kws(chunk)\n",
        "\n",
        "      doc_objs.append({\n",
        "        'document_id': doc_id,\n",
        "        'chunk_text': chunk,\n",
        "        'chunk_index': idx,\n",
        "        'keywords': ' '.join([*doc_keywords, *chunk_keywords]),\n",
        "      })\n",
        "\n",
        "  return doc_objs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9t4D_sG6gFpt"
      },
      "outputs": [],
      "source": [
        "with WeaviateClientSession() as client:\n",
        "  client.connect()\n",
        "  doc_objs = prepare_doc_objs(documents)\n",
        "  documents_coll = client.collections.get(\"Documents\")\n",
        "  documents_coll.data.insert_many(doc_objs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tFsnbSLnnoC"
      },
      "source": [
        "## Perform hybrid search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3JP99Z2Cnsls"
      },
      "outputs": [],
      "source": [
        "def perform_search(query: str, n: int = 5, alpha: float = 0.25) -> list[dict]:\n",
        "  with WeaviateClientSession() as client:\n",
        "      documents_coll = client.collections.get(\"Documents\")\n",
        "      response = documents_coll.query.hybrid(\n",
        "          query=query,\n",
        "          query_properties=[\"keywords\"],\n",
        "          # fusion_type=wvc.query.HybridFusion.RELATIVE_SCORE, # we need to use the score fusion (not rank) for autocut\n",
        "          # auto_limit=1, # we only want one jump\n",
        "          alpha=alpha,\n",
        "          limit=n,\n",
        "      )\n",
        "\n",
        "      for o in response.objects:\n",
        "          print(o.properties)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ySOD-E3bvvFZ"
      },
      "outputs": [],
      "source": [
        "perform_search(query_2)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}